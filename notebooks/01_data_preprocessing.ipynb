{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79ee11e",
   "metadata": {},
   "source": [
    "# 01 - Data Preprocessing\n",
    "\n",
    "This notebook handles:\n",
    "- Mounting Google Drive (if applicable)\n",
    "- Extracting and loading the dataset\n",
    "- Listing and organizing the files\n",
    "- Preliminary checks on structure and formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive if using Colab (comment out if running locally)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc73b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and unzip the dataset path\n",
    "import zipfile\n",
    "\n",
    "zip_path = '/content/drive/My Drive/HACKATON HERA/wetransfer_inrete-ai-data-hackathon_2024-11-26_0803.zip'\n",
    "extract_path = '/content/InRete_Data'\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in the dataset\n",
    "import os\n",
    "\n",
    "def list_all_files(folder_path):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    return file_paths\n",
    "\n",
    "folder_path = extract_path\n",
    "all_files = list_all_files(folder_path)\n",
    "\n",
    "print('Found files:')\n",
    "for f in all_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for relevant files\n",
    "tratte_disp = [p for p in all_files if 'tratte_disp' in p]\n",
    "tratte_gas = [p for p in all_files if 'tratte_gas' in p]\n",
    "rischio = [p for p in all_files if 'part' in p]\n",
    "\n",
    "print('\\nTratte Dispersione:')\n",
    "for f in tratte_disp:\n",
    "    print(f)\n",
    "\n",
    "print('\\nTratte Gas:')\n",
    "for f in tratte_gas:\n",
    "    print(f)\n",
    "\n",
    "print('\\nRischio:')\n",
    "for f in rischio:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into memory\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "tratte_disp_df = pd.concat([pd.read_parquet(t) for t in tratte_disp], ignore_index=True)\n",
    "tratte_gas_df = [gpd.read_parquet(t) for t in tratte_gas]\n",
    "rischio_df = pd.concat([pd.read_parquet(t) for t in rischio], ignore_index=True)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
