{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f723eefa",
   "metadata": {},
   "source": [
    "# 03 - Model Training\n",
    "\n",
    "This notebook covers:\n",
    "- Joining features and aggregating data\n",
    "- Creating lag features\n",
    "- Training classification and regression models\n",
    "- Evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d40986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets and create lags\n",
    "df_finale = pd.merge(disp_by_codsistema, aggregated, on=['CODSISTEMA', 'YEAR'], how='right')\n",
    "df_finale = df_finale.sort_values(['CODSISTEMA', 'YEAR', 'MONTH'])\n",
    "\n",
    "for lag in range(1, 7):\n",
    "    df_finale[f'dispersione_lag_{lag}'] = (\n",
    "        df_finale.groupby('CODSISTEMA')['dispersione'].shift(lag)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f08fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "train = df_finale[df_finale.YEAR != 2022]\n",
    "test = df_finale[df_finale.YEAR == 2022]\n",
    "\n",
    "# Binary classifier\n",
    "X_train_binary = train.drop(columns='dispersione')\n",
    "X_test_binary = test.drop(columns='dispersione')\n",
    "y_train_binary = (train.dispersione > 0).astype(int)\n",
    "y_test_binary = (test.dispersione > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f82e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM classifier\n",
    "clf = lgb.LGBMClassifier(verbosity=-1)\n",
    "clf.fit(X_train_binary.fillna(0).values, y_train_binary)\n",
    "preds_bin = clf.predict(X_test_binary.fillna(0).values)\n",
    "\n",
    "print('F1 Score:', f1_score(y_test_binary, preds_bin, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressor (only on non-zero targets)\n",
    "train_reg = train[train.dispersione != 0]\n",
    "test_reg = test[test.dispersione != 0]\n",
    "\n",
    "X_train_reg = train_reg.drop(columns='dispersione')\n",
    "X_test_reg = test_reg.drop(columns='dispersione')\n",
    "y_train_reg = train_reg.dispersione\n",
    "y_test_reg = test_reg.dispersione\n",
    "\n",
    "reg = lgb.LGBMRegressor(verbosity=-1)\n",
    "reg.fit(X_train_reg.fillna(0).values, y_train_reg)\n",
    "preds_reg = reg.predict(X_test_reg.fillna(0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a78614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate regression performance\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "baseline_mae = abs(y_test_reg - y_test_reg.mean()).mean()\n",
    "actual_mae = mean_absolute_error(y_test_reg, preds_reg)\n",
    "\n",
    "print('Baseline MAE:', baseline_mae)\n",
    "print('Model MAE:', actual_mae)\n",
    "print('Improvement ratio:', actual_mae / baseline_mae)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
